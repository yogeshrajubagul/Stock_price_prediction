{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Main Objectives:\n",
        "The scope of this project is to build several deep learning algorithms based on RNN techniques which can predict future values of an indicator using Time-Series Forecasting methods in order to achieve the highest possible accuracy. This can be broken down into the following milestones:\n",
        "\n",
        "Data Exploration and evaluation of Stationarity. Modeling and selection of best model. Prediction of future values."
      ],
      "metadata": {
        "id": "FA8jhqebTAgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "metadata": {
        "id": "I-dMxuQNTOCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "df=pd.read_csv('yahoo_stock.csv')"
      ],
      "metadata": {
        "id": "0d5GGy8aGSC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "JN2RAzVnS5YM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam\n",
        "import statistics"
      ],
      "metadata": {
        "id": "xNM2eYPdS5br"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "E4Fy5UItS5e7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "F5uwfWDpS5hz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our dataset contains 6 columns of indicators and date columns which will be then set as index. Now let's see if the dates are unique or if there are duplicate values."
      ],
      "metadata": {
        "id": "EF17MB1DTdiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import date"
      ],
      "metadata": {
        "id": "TZCjkVyPUoxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df['Date'].unique())"
      ],
      "metadata": {
        "id": "XaErfqwDS5lL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As there are 1825 unique dates means that each one corresponds to unique records in the table, therefore we don't have duplicated or inconsistent values."
      ],
      "metadata": {
        "id": "gx03OnqdTl3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "GXTqU9zlS5oX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "bRnfxt_ZS5rL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "9BDDCb3WS5ut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the date column is wrongly set as object type, let's change it to Datetime type:"
      ],
      "metadata": {
        "id": "9J8SSWUJUPKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.Date=pd.to_datetime(df['Date'])"
      ],
      "metadata": {
        "id": "qESR5RKkS5xY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.Date.min(),df.Date.max()"
      ],
      "metadata": {
        "id": "6TnwgOJOS5zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's compute the amount of days between the limits in the table, i.e. 2020-11-20/2015-11-23, take into account that the result will give us the days-1:"
      ],
      "metadata": {
        "id": "L4LJZrijP_48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.Date.max()-df.Date.min()"
      ],
      "metadata": {
        "id": "jb40OASxS52r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting the date as index will make our time series plots much more understandable."
      ],
      "metadata": {
        "id": "pwtTSNq1QFyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.set_index('Date',inplace=True)"
      ],
      "metadata": {
        "id": "CkxilTqVS55j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "hNFGOtogS58b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's plot four of the indicators in the table and differentiate their corresponding curves by colours."
      ],
      "metadata": {
        "id": "9JOeFBTTQQD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[['High','Low','Open','Close']].plot(figsize = (15, 5), alpha = 0.5)"
      ],
      "metadata": {
        "id": "-O96pH50S5_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The four had almost same behaviour troughout time and based on this assumption in this project we will only focus on one of them 'High' in order to build a model which could predict future values and then as possible suggestions extrapolate such model to other indicators. Firstly, we will demonstrate if the time-series problem corresponds to a Non-Stationary type, which characterizes for having:\n",
        "\n",
        "Non-constant variance./n Non-constant mean. Seasonality. High autocorrelation.\n",
        "\n",
        "There are four well known ways to evaluate if the serie meets the criteria just mentioned, these corresponds to:\n",
        "\n",
        "Sequence visualization. Histogram, Autocorrelation and Partial Aurocorrelation plots. Statistical summary of chunks. Adfuller test.\n",
        "\n",
        "# Evaluating Stationarity:\n",
        "The following histogram plot should have a uniform distribution meaning non-constant mean or 'trend':"
      ],
      "metadata": {
        "id": "EZ0xCVaFQaTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.High.hist(bins=50)"
      ],
      "metadata": {
        "id": "6TA-ZOB2S6Cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can't assume a uniform nor normal distribution in the plot above, because of that the statistical summary can helps us more, for this we will split the data into 10 chunks and compute mean and variance of each one."
      ],
      "metadata": {
        "id": "NHEkYO8WQmga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.round(df.shape[0]/10,0)"
      ],
      "metadata": {
        "id": "xVTWw6XnS6Fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statistics import stdev\n",
        "mean=[]\n",
        "std=[]\n",
        "\n",
        "for i in range(0,10):\n",
        "    mean.append(df['High'].iloc[(i*182):(i*182)+182].mean())\n",
        "    std.append(stdev(df['High'].iloc[(i*182):(i*182)+182]))"
      ],
      "metadata": {
        "id": "h3zQzCIzS6JF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([pd.DataFrame(mean,columns=['mean']),pd.DataFrame(std,columns=['std'])], axis=1)"
      ],
      "metadata": {
        "id": "VmitXrP3S6MD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above we see how both measures are clearly different in each chunk. However looking at the plot we could assume a constant variance as the ripple in the curve, but without a doubt trend is the most outstanding feature. Until now can assume it's a non-stationary serie, but to know more about it we will evaluate two other methods. Seasonal decomposition is a function from statsmodels library which allows us to decompose the serie into trend, seasonal and residual, either additive or multiplicative:"
      ],
      "metadata": {
        "id": "9Uav_kG6Q0Tq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.seasonal import seasonal_decompose"
      ],
      "metadata": {
        "id": "ajUepGjYS6PU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decompose_add=seasonal_decompose(df['High'], model='additive', period=12)\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.subplot(411)\n",
        "plt.plot(df['High'], label='Original TS')\n",
        "plt.legend(loc='best')\n",
        "plt.subplot(412)\n",
        "plt.plot(decompose_add.trend, label='Trend')\n",
        "plt.legend(loc='best')\n",
        "plt.subplot(413)\n",
        "plt.plot(decompose_add.seasonal,label='Seasonality')\n",
        "plt.legend(loc='best')\n",
        "plt.subplot(414)\n",
        "plt.plot(decompose_add.resid, label='Residual')\n",
        "plt.legend(loc='best')"
      ],
      "metadata": {
        "id": "-7ZR6P20S6Sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decompose_mul=seasonal_decompose(df['High'], model='multiplicative', period=12)\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.subplot(411)\n",
        "plt.plot(df['High'], label='Original TS')\n",
        "plt.legend(loc='best')\n",
        "plt.subplot(412)\n",
        "plt.plot(decompose_mul.trend, label='Trend')\n",
        "plt.legend(loc='best')\n",
        "plt.subplot(413)\n",
        "plt.plot(decompose_mul.seasonal,label='Seasonality')\n",
        "plt.legend(loc='best')\n",
        "plt.subplot(414)\n",
        "plt.plot(decompose_mul.resid, label='Residual')\n",
        "plt.legend(loc='best')"
      ],
      "metadata": {
        "id": "fazlXs-QS6Vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking carefully to the original curve we can say the additive decomposition makes more sense as the trend does not seem to be changing by the multiplication with seasonal component, rather every component seems to being added up to create the original curve. Independent of this there is a trend and seasonal component. Below we can see the ACF and PACF plots:"
      ],
      "metadata": {
        "id": "VkTy87NrRDaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.graphics.tsaplots import plot_acf\n",
        "from statsmodels.graphics.tsaplots import plot_pacf"
      ],
      "metadata": {
        "id": "8TXL3TG8S6ZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rc(\"figure\", figsize=(10,5))\n",
        "plot_acf(df['High'])\n",
        "print()"
      ],
      "metadata": {
        "id": "ccJB6qJcS6ez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rc(\"figure\", figsize=(10,5))\n",
        "plot_pacf(df['High'])\n",
        "print()"
      ],
      "metadata": {
        "id": "9mhOcJtDS6hz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we will make the Augmented Dickey-Fuller test, using 5% as significance level and declaring the following hypothesis:\n",
        "\n",
        "H0= Serie corresponds to non-stationary type. H1= Serie corresponds to stationary type."
      ],
      "metadata": {
        "id": "4Ba29QC2RQoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.stattools import adfuller"
      ],
      "metadata": {
        "id": "MhyPg9DBS6nD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = adfuller(df['High'])\n",
        "print('ADF Statistic: %f' % result[0])\n",
        "print('p-value: %f' % result[1])\n",
        "print('Critical Values:')\n",
        "for key, value in result[4].items():\n",
        "    print('\\t%s: %.3f' % (key, value))"
      ],
      "metadata": {
        "id": "LRzb10vPS6ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As p-value is greater than 0.05 we fail to reject the null hypothesis, therefore there is not enough evidence to reject that we are working with a non-stationary series. Let's apply the log transformation to the serie and test again."
      ],
      "metadata": {
        "id": "b5LbMMHmRdHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import log\n",
        "\n",
        "result = adfuller(log(df['High']))\n",
        "print('ADF Statistic: %f' % result[0])\n",
        "print('p-value: %f' % result[1])\n",
        "print('Critical Values:')\n",
        "for key, value in result[4].items():\n",
        "    print('\\t%s: %.3f' % (key, value))"
      ],
      "metadata": {
        "id": "a30qRshcS6t_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on every method applied we can endorse the serie clearly corresponds to a non-stationary type, which means that we have to convert this to stationary by using filters and complex transformations. However, deep learning approaches can lead us to build models which takes into account all of these characteristics and predict future values modestly, but as disadvantage it would take significantly more time to train such models.\n",
        "\n",
        "## Modeling:\n",
        "In order to choose the best model 4 changes in hyperparameters and architecture will be applied and then evaluate each one by computing their corresponding error metrics. The purpose of this method is to find the appropriate characteristics of the model by looking at the effect of regularization, window length, number of epochs and type of cell. Each step will be denominated ‘comparison’ and are detailed as follows:\n",
        "\n",
        "● 1st comparison, model with 7 different window length. ● 2nd comparison, model with more layers, neurons and epochs. ● 3rd comparison, model with regularization. ● 4th comparison, model using SimpleRNN vs LSTM.\n",
        "\n",
        "Firstly, we will define a new dataset equal to the existing one, but omitting the last four records, later we will use the model to predict such values."
      ],
      "metadata": {
        "id": "kFrsTfvpRkvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_df=df['High'].iloc[:-4]"
      ],
      "metadata": {
        "id": "xow0XELwS6w3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define the length of the training set as 80% of the total records (specifically the first 80% of data, i.e.: from record 0 to record 1456):"
      ],
      "metadata": {
        "id": "Tfss8mOARuKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_len = math.ceil(len(new_df)*0.8)\n",
        "train_len"
      ],
      "metadata": {
        "id": "iD6dKZcjS60B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use 10 as a random window to be used in the model to build:"
      ],
      "metadata": {
        "id": "1Br5tBhqRznn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "window=10"
      ],
      "metadata": {
        "id": "Gs0s3k2jS63b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following lines create the training sets, as we now the first row takes the first 10 time steps and then the second row takes time steps shifted in one and so on and so forth:"
      ],
      "metadata": {
        "id": "DGI51_6rR4rm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = new_df[0:train_len]\n",
        "\n",
        "X_train=[]\n",
        "Y_train=[]\n",
        "\n",
        "for i in range(window, len(train_data)):\n",
        "    X_train.append(train_data[i-window:i])\n",
        "    Y_train.append(train_data[i])"
      ],
      "metadata": {
        "id": "KZFA3oMnS677"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train= np.array(X_train), np.array(Y_train)"
      ],
      "metadata": {
        "id": "zq5dZF_PS6_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reshaping the training set to (number of records-window, number of time steps, 1):"
      ],
      "metadata": {
        "id": "S9sGI7_9SBMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "X_train.shape"
      ],
      "metadata": {
        "id": "x03CbOJzS7C6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "Kc_PbSMDS7GE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following is the first model to be used, this is relatively simple with one LSTM layer with relu activation function and one hidden fully connected layer, the optimizer used is Adam, number of epochs=10, batch_size=10 and loss function=Mean squared error:"
      ],
      "metadata": {
        "id": "dDLlGkwwSK_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout"
      ],
      "metadata": {
        "id": "Gwv1wBa5S7I7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(LSTM(50, activation='relu', input_shape=(X_train.shape[1],1)))\n",
        "model.add(Dense(25))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model.summary()\n",
        "model.fit(X_train, Y_train, epochs=10, batch_size=10, verbose=0)"
      ],
      "metadata": {
        "id": "B-dgbS0mS7MU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the validation set using same logic as training:"
      ],
      "metadata": {
        "id": "tiuIXOj6Sa5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = new_df[train_len-window:]\n",
        "\n",
        "X_val=[]\n",
        "Y_val=[]\n",
        "\n",
        "for i in range(window, len(test_data)):\n",
        "    X_val.append(test_data[i-window:i])\n",
        "    Y_val.append(test_data[i])"
      ],
      "metadata": {
        "id": "bsENZSjESUG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_val, Y_val = np.array(X_val), np.array(Y_val)\n",
        "X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1],1))"
      ],
      "metadata": {
        "id": "pCSPb_WHSUKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_val.shape, Y_val.shape"
      ],
      "metadata": {
        "id": "xscJwDW3SURw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that our validation set has the correct shape we can use it in the model to predict the next value."
      ],
      "metadata": {
        "id": "qYtXsb96SkaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.predict(X_val)"
      ],
      "metadata": {
        "id": "e3D_i7onSUU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(prediction), len(Y_val)"
      ],
      "metadata": {
        "id": "wTc02oGHSUYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As our prediction and actual values have the same shape we can use these sets to compute the error metrics, in this case we will use RMSE."
      ],
      "metadata": {
        "id": "LGe-bO_UStJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "lstm_train_pred = model.predict(X_train)\n",
        "lstm_valid_pred = model.predict(X_val)\n",
        "print('Train rmse:', np.sqrt(mean_squared_error(Y_train, lstm_train_pred)))\n",
        "print('Validation rmse:', np.sqrt(mean_squared_error(Y_val, lstm_valid_pred)))"
      ],
      "metadata": {
        "id": "RPiGx3AMSUbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both errors are high, if we specifically see the validation one we could say it's too much and we aim to improve this as we build a robust model in the next steps. Below is a table which merged the actual and predicted values, therefore we can see for each record how differ these two and have an idea of how sidetracked we currently are."
      ],
      "metadata": {
        "id": "HkOiCp4LS188"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "valid = pd.DataFrame(new_df[train_len:])\n",
        "valid['Predictions']=lstm_valid_pred\n",
        "valid"
      ],
      "metadata": {
        "id": "P4zWPcd5SUet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we can see a simple plot showing both curves, in which clearly there is a difference and a sort of shift to the right or delay in the prediction curve."
      ],
      "metadata": {
        "id": "MiM8Dry0THwr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(valid[['High','Predictions']])\n",
        "plt.legend(['Validation','Predictions'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "elN0aeVrSUlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, the plot showing training, validation and prediction curves:"
      ],
      "metadata": {
        "id": "978z92t4TNgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = new_df[:train_len]\n",
        "valid = pd.DataFrame(new_df[train_len:])\n",
        "valid['Predictions']=lstm_valid_pred\n",
        "\n",
        "plt.figure(figsize=(16,8))\n",
        "plt.title('Model LSTM')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Close Price USD')\n",
        "plt.plot(train)\n",
        "plt.plot(valid[['High','Predictions']])\n",
        "plt.legend(['Train','Val','Predictions'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1xOJZdV9SUpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1st comparison:\n",
        "In order to tackle down this 'shift' and thus reduce the error we have to find the suit window number, for this we will compute the RMSE for the following number of windows: 5,8,10,15,20,30,40. Then compare results and find the lowest."
      ],
      "metadata": {
        "id": "oLjqBSmVTUt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_error=[]\n",
        "val_error=[]\n",
        "\n",
        "window_number=[5,8,10,15,20,30,40]\n",
        "for i in window_number:\n",
        "    #_____________________________________________________________________\n",
        "    train_data = new_df[0:train_len]\n",
        "\n",
        "    X_train=[]\n",
        "    Y_train=[]\n",
        "\n",
        "    for i in range(window, len(train_data)):\n",
        "        X_train.append(train_data[i-window:i])\n",
        "        Y_train.append(train_data[i])\n",
        "\n",
        "    X_train, Y_train= np.array(X_train), np.array(Y_train)\n",
        "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "    #______________________________________________________________________\n",
        "    test_data = new_df[train_len-window:]\n",
        "\n",
        "    X_val=[]\n",
        "    Y_val=[]\n",
        "\n",
        "    for i in range(window, len(test_data)):\n",
        "        X_val.append(test_data[i-window:i])\n",
        "        Y_val.append(test_data[i])\n",
        "\n",
        "    X_val, Y_val = np.array(X_val), np.array(Y_val)\n",
        "    X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1],1))\n",
        "    #______________________________________________________________________\n",
        "    model=Sequential()\n",
        "    model.add(LSTM(50, activation='relu', input_shape=(X_train.shape[1],1)))\n",
        "    model.add(Dense(25))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    model.fit(X_train, Y_train, epochs=10, batch_size=10, verbose=0)\n",
        "    #______________________________________________________________________\n",
        "    lstm_train_pred = model.predict(X_train)\n",
        "    lstm_valid_pred = model.predict(X_val)\n",
        "    train_error.append(np.sqrt(mean_squared_error(Y_train, lstm_train_pred)))\n",
        "    val_error.append(np.sqrt(mean_squared_error(Y_val, lstm_valid_pred)))"
      ],
      "metadata": {
        "id": "iyF-tCqRSUxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_error"
      ],
      "metadata": {
        "id": "tvSRQQx_SU0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_error"
      ],
      "metadata": {
        "id": "dgbYXcQpSU6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following table shows the RMSE of train and validation sets for each of the 7 windows:"
      ],
      "metadata": {
        "id": "XOynE_tlTobM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([pd.DataFrame(train_error,columns=['train_error']),\n",
        "           pd.DataFrame(val_error,columns=['val_error']),\n",
        "           pd.DataFrame([5,8,10,15,20,30,40],columns=['window'])], axis=1).set_index('window')"
      ],
      "metadata": {
        "id": "OPkjmjJvSU9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: Each time that I ran the prior code of 7 windows the outcome was different, but in general the behaviour was as in the table above, having window=10 the lowest RMSE for validation set. Thus this number was chosen as the best predictor. Even though before we have seen how for this value the shift was significant for all other windows this difference was much more, but there are still more hyperparameters to tune in order to improve the accuracy.\n",
        "\n",
        "# 2nd comparison:\n",
        "One efficient way to improve the accuracy is by simply increasing the complexity of the model and this can be achieved adding more layers and more LSTM cells. Therefore in this step we will build a multilayered model and compare its performance with the prior. Firstly, let's create again the training and validation sets for 10 windows to be used."
      ],
      "metadata": {
        "id": "jkYLFDcxT_sJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "window=10\n",
        "\n",
        "train_data = new_df[0:train_len]\n",
        "X_train=[]\n",
        "Y_train=[]\n",
        "for i in range(window, len(train_data)):\n",
        "    X_train.append(train_data[i-window:i])\n",
        "    Y_train.append(train_data[i])\n",
        "\n",
        "X_train, Y_train= np.array(X_train), np.array(Y_train)\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "#____________________________________________________________________\n",
        "test_data = new_df[train_len-window:]\n",
        "X_val=[]\n",
        "Y_val=[]\n",
        "for i in range(window, len(test_data)):\n",
        "    X_val.append(test_data[i-window:i])\n",
        "    Y_val.append(test_data[i])\n",
        "\n",
        "X_val, Y_val = np.array(X_val), np.array(Y_val)\n",
        "X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1],1))"
      ],
      "metadata": {
        "id": "CVqM7LHESVBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following is the architecture of the model to be used (2 LSTM layers and 2 hidden fully-connected layers), the optimizer is more specific and the number of epochs was increased to 100:"
      ],
      "metadata": {
        "id": "cB8OYOqvUKOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(LSTM(50,return_sequences=True, activation='relu', input_shape=(X_train.shape[1],1)))\n",
        "model.add(LSTM(50,return_sequences=False,activation='relu'))\n",
        "model.add(Dense(100))\n",
        "model.add(Dense(25))\n",
        "model.add(Dense(1))\n",
        "opt1=Adam(learning_rate=0.001,beta_1=0.9,beta_2=0.999)\n",
        "model.compile(loss='mean_squared_error', optimizer=opt1)\n",
        "model.summary()\n",
        "model.fit(X_train, Y_train, epochs=100, batch_size=10, verbose=0)"
      ],
      "metadata": {
        "id": "ZwBb1KgYSVFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the summary above we can see that the total parameters of this new model is three times or even more than the prior which is indicative of the complexity and the time it takes to train."
      ],
      "metadata": {
        "id": "rc4YH04sUSFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_train_pred = model.predict(X_train)\n",
        "lstm_valid_pred = model.predict(X_val)\n",
        "print('Train rmse:', np.sqrt(mean_squared_error(Y_train, lstm_train_pred)))\n",
        "print('Validation rmse:', np.sqrt(mean_squared_error(Y_val, lstm_valid_pred)))"
      ],
      "metadata": {
        "id": "aKaovg8aSVIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid = pd.DataFrame(new_df[train_len:])\n",
        "valid['Predictions']=lstm_valid_pred"
      ],
      "metadata": {
        "id": "-Os1IrBTSVLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(valid[['High','Predictions']])\n",
        "plt.legend(['Validation','Predictions'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jajTwd0pSVOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Despite the fact that error metrics were lower than before in the plot above still can see a gap between the actual and predicted values. Again, I've found that each time I ran this model the results were different and the current output corresponds to the very best one, but in order to better vizualize this I will run 10 times the same model and compute the errors in each one."
      ],
      "metadata": {
        "id": "qJSRbPx-UiPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r1=[]\n",
        "r2=[]\n",
        "\n",
        "for i in range(0,10):\n",
        "    model=Sequential()\n",
        "    model.add(LSTM(50,return_sequences=True, activation='relu', input_shape=(X_train.shape[1],1)))\n",
        "    model.add(LSTM(50,return_sequences=False,activation='relu'))\n",
        "    model.add(Dense(100))\n",
        "    model.add(Dense(25))\n",
        "    model.add(Dense(1))\n",
        "    opt1=Adam(learning_rate=0.001,beta_1=0.9,beta_2=0.999)\n",
        "    model.compile(loss='mean_squared_error', optimizer=opt1)\n",
        "    model.fit(X_train, Y_train, epochs=100, batch_size=10,verbose=0)\n",
        "\n",
        "    lstm_train_pred = model.predict(X_train)\n",
        "    lstm_valid_pred = model.predict(X_val)\n",
        "    r1.append(np.round(np.sqrt(mean_squared_error(Y_train, lstm_train_pred)),2))\n",
        "    r2.append(np.round(np.sqrt(mean_squared_error(Y_val, lstm_valid_pred)),2))"
      ],
      "metadata": {
        "id": "SCfFXf06SVR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we can see the RMSE for each time, note that these are considerably different, being still more impactful in the validation set."
      ],
      "metadata": {
        "id": "ewyIZtsqWZcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r1, statistics.mean(r1), statistics.stdev(r1)"
      ],
      "metadata": {
        "id": "R6gfr17PSVVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2, statistics.mean(r2), statistics.stdev(r2)"
      ],
      "metadata": {
        "id": "_gPWTPPpSVY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see how validation errors are higher than training and also more spreaded because of such stardard deviation.\n",
        "\n",
        "## 3rd comparison:¶\n",
        "As the validation errors were still considerably higher than training we think one reason could be due to overfitting and for this problem we have to add regularization to the model chosen by using Dropout after Fully Connected layers and LSTM cells. In this step we will run a regularized model again 10 times in order to see the variation in the results:"
      ],
      "metadata": {
        "id": "p9LkIkW7Wf_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r1=[]\n",
        "r2=[]\n",
        "\n",
        "for i in range(0,10):\n",
        "    model=Sequential()\n",
        "    model.add(LSTM(50,return_sequences=True, activation='relu', input_shape=(X_train.shape[1],1),recurrent_dropout=0.2))\n",
        "    model.add(LSTM(50,return_sequences=False,activation='relu'))\n",
        "    model.add(Dense(100))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(25))\n",
        "    model.add(Dense(1))\n",
        "    opt1=Adam(learning_rate=0.001,beta_1=0.9,beta_2=0.999)\n",
        "    model.compile(loss='mean_squared_error', optimizer=opt1)\n",
        "    model.fit(X_train, Y_train, epochs=100, batch_size=10,verbose=0)\n",
        "\n",
        "    lstm_train_pred = model.predict(X_train)\n",
        "    lstm_valid_pred = model.predict(X_val)\n",
        "    r1.append(np.round(np.sqrt(mean_squared_error(Y_train, lstm_train_pred)),2))\n",
        "    r2.append(np.round(np.sqrt(mean_squared_error(Y_val, lstm_valid_pred)),2))"
      ],
      "metadata": {
        "id": "B-Y3tg_sSVcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r1, statistics.mean(r1), statistics.stdev(r1)"
      ],
      "metadata": {
        "id": "IpORoLchSVff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2, statistics.mean(r2), statistics.stdev(r2)"
      ],
      "metadata": {
        "id": "EZa4Cx31SVip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see above how these values either training or validation were higher than without dropout, which is definitely not good. Note: Different levels of dropout were used above from 0.1 to 0.6 obtaining similar or higher errors. Now that we saw dropout did not reduce the errors we can not attribute the problem to overfitting and a different approach must be taken. For your consideration I have also changed the optimizer to Adadelta, Adamax, RMSProp and SGD but everyone had higher error or simply did not work, the activation function was changed to tanh and sigmoid obtaining similar errors.\n",
        "\n",
        "# 4th comparison:\n",
        "Until now every model built does not offer us a good accuracy, as we are dealing with the budget of a company this results can lead to a completely wrong decision, but as I said there is still a room of improvement and different approaches must be taken. We were forgeting the simplest type of RNN which is known for being more affected by vanishing gradient, however for our dataset it worked as follows (Again the model will be run 10 times):\n"
      ],
      "metadata": {
        "id": "6nf7astLW9A4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import SimpleRNN"
      ],
      "metadata": {
        "id": "S656RmHtSVmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r1=[]\n",
        "r2=[]\n",
        "\n",
        "for i in range(0,10):\n",
        "    model=Sequential()\n",
        "    model.add(SimpleRNN(50,return_sequences=True, activation='relu', input_shape=(X_train.shape[1],1)))\n",
        "    model.add(SimpleRNN(50,return_sequences=False,activation='relu'))\n",
        "    model.add(Dense(100))\n",
        "    model.add(Dense(25))\n",
        "    model.add(Dense(1))\n",
        "    opt1=Adam(learning_rate=0.001,beta_1=0.9,beta_2=0.999)\n",
        "    model.compile(loss='mean_squared_error', optimizer=opt1)\n",
        "    model.fit(X_train, Y_train, epochs=100, batch_size=10,verbose=0)\n",
        "\n",
        "    lstm_train_pred = model.predict(X_train)\n",
        "    lstm_valid_pred = model.predict(X_val)\n",
        "    r1.append(np.round(np.sqrt(mean_squared_error(Y_train, lstm_train_pred)),2))\n",
        "    r2.append(np.round(np.sqrt(mean_squared_error(Y_val, lstm_valid_pred)),2))"
      ],
      "metadata": {
        "id": "9tDQgdrySVqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r1, statistics.mean(r1), statistics.stdev(r1)"
      ],
      "metadata": {
        "id": "Lixkl6crSVul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2, statistics.mean(r2), statistics.stdev(r2)"
      ],
      "metadata": {
        "id": "sZ_S2C0FSVxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wow!, even less than half the prior error metrics and what is more important is the fact that stardard deviation is much lower, which tells us that the model offer a more stable performance using RNNs rather than LSTMs. Translating this to a more meaningful way the average error in the validation set reaches 41 USD with a std a bit higher than 4 USD. Let's plot the actual and predicted values for the validation set and see how reduced was the 'shift':"
      ],
      "metadata": {
        "id": "Pcsi3RNLXebX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "valid = pd.DataFrame(new_df[train_len:])\n",
        "valid['Predictions']=lstm_valid_pred\n",
        "valid"
      ],
      "metadata": {
        "id": "aZIs3p_DSV0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(valid[['High','Predictions']])\n",
        "plt.legend(['Validation','Predictions'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VIl4JepZSV4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clearly, the gap was reduced significantly and the predicted curve even responded quickly to the 'high frequencies' or a.k.a. ripple in the actual curve. As this model corresponds to the best one we will continue working with this.\n",
        "\n",
        "In order to get a bit better results from the previous model I will use a callback to find the learning rate wich offers the lowest MSE loss. I have already shorten the range to [1e-5 - 1e-3] and found that around 1e-4 and beta2 = 0.7 occurrs the lowest error, therefore these were chosen to rebuild the model:"
      ],
      "metadata": {
        "id": "NhjWNPdTXrnQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "\n",
        "r1=[]\n",
        "r2=[]\n",
        "\n",
        "model=Sequential()\n",
        "model.add(SimpleRNN(50,return_sequences=True, activation='relu', input_shape=(X_train.shape[1],1)))\n",
        "model.add(SimpleRNN(50,return_sequences=False,activation='relu'))\n",
        "model.add(Dense(100))\n",
        "model.add(Dense(25))\n",
        "model.add(Dense(1))\n",
        "lr_schedule = tensorflow.keras.callbacks.LearningRateScheduler(\n",
        "    lambda epoch: 1e-5 * 10**(epoch / 85))\n",
        "opt1=Adam(learning_rate=1e-5,beta_1=0.9,beta_2=0.7)\n",
        "model.compile(loss='mean_squared_error', optimizer=opt1)\n",
        "history=model.fit(X_train, Y_train, epochs=100, batch_size=10,verbose=2, callbacks=[lr_schedule])\n",
        "\n",
        "lstm_train_pred = model.predict(X_train)\n",
        "lstm_valid_pred = model.predict(X_val)\n",
        "r_train_new=np.round(np.sqrt(mean_squared_error(Y_train, lstm_train_pred)),2)\n",
        "r_val_new=np.round(np.sqrt(mean_squared_error(Y_val, lstm_valid_pred)),2)"
      ],
      "metadata": {
        "id": "bTOEeFFFSV7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\n",
        "plt.axis([1e-5, 5e-4, 0, 1000])"
      ],
      "metadata": {
        "id": "-UUL_m9FS7PU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that I have the best hyperparameters I will build again the model and evaluate its performance 15 times:"
      ],
      "metadata": {
        "id": "EBS6rSxmX1hv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r1=[]\n",
        "r2=[]\n",
        "\n",
        "for i in range(0,10):\n",
        "    model=Sequential()\n",
        "    model.add(SimpleRNN(50,return_sequences=True, activation='relu', input_shape=(X_train.shape[1],1)))\n",
        "    model.add(SimpleRNN(50,return_sequences=False,activation='relu'))\n",
        "    model.add(Dense(100))\n",
        "    model.add(Dense(25))\n",
        "    model.add(Dense(1))\n",
        "    opt1=Adam(learning_rate=1e-4,beta_1=0.9,beta_2=0.7)\n",
        "    model.compile(loss='mean_squared_error', optimizer=opt1)\n",
        "    model.fit(X_train, Y_train, epochs=100, batch_size=10,verbose=0)\n",
        "\n",
        "    lstm_train_pred = model.predict(X_train)\n",
        "    lstm_valid_pred = model.predict(X_val)\n",
        "    1 r1.append(np.round(np.sqrt(mean_squared_error(Y_train, lstm_train_pred)),2))\n",
        "    2 r2.append(np.round(np.sqrt(mean_squared_error(Y_val, lstm_valid_pred)),2))\n",
        ""
      ],
      "metadata": {
        "id": "6HxZtSeAS7Sd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r1, statistics.mean(r1), statistics.stdev(r1)"
      ],
      "metadata": {
        "id": "3gJfTNe4S7Vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2, statistics.mean(r2), statistics.stdev(r2)"
      ],
      "metadata": {
        "id": "0LLd38I6S7Yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The four metrics were reduced by chosing the right learning rate and betas, this made our model a bit more reliable as we will see next in the prediction:"
      ],
      "metadata": {
        "id": "Zi-a6yzTYCem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "valid = pd.DataFrame(new_df[train_len:])\n",
        "valid['Predictions']=lstm_valid_pred\n",
        "valid"
      ],
      "metadata": {
        "id": "csXYOedbS7bu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(valid[['High','Predictions']])\n",
        "plt.legend(['Validation','Predictions'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BsWVaaqcS7e7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting 'future' values:\n",
        "As we have values until 16-11-2020 we can predict the next one using the model built and compare the outcome with the actual value saved in the original dataframe 'df':"
      ],
      "metadata": {
        "id": "5o1HKc-aYKh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "last_10_days=new_df[-10:].values\n",
        "X_test=[]\n",
        "X_test.append(last_10_days)\n",
        "X_test=np.array(X_test)\n",
        "X_test=np.reshape(X_test,(X_test.shape[0],X_test.shape[1],1))\n",
        "pred_price=model.predict(X_test)\n",
        "print(pred_price)"
      ],
      "metadata": {
        "id": "DkkYd6StS7l3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's find the corresponding actual value in df:"
      ],
      "metadata": {
        "id": "JLNdAiHtYUa-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['High'].iloc[-4]"
      ],
      "metadata": {
        "id": "c-kzKAW3S7pt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The difference is less than $18 USD and the model seems to be working very good.\n",
        "\n",
        "Predicting 4 future values:"
      ],
      "metadata": {
        "id": "ohALihp4YbgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.High.tail(14)"
      ],
      "metadata": {
        "id": "2gt7zUd2S7s0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above, the last 4 values correspond to the actual values we want to predict, and the time steps used does not comprehend these rather will be used the predicted ones as we run the model. As we predicted one value (pred_price) the time steps used to predict a new one will take the last 9 of new_df and pred_price, as follows:"
      ],
      "metadata": {
        "id": "K66Z6dCmYhdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "last_9_days=new_df[-9:].values\n",
        "X_test=[]\n",
        "X_test=np.append(last_9_days,pred_price)\n",
        "X_test=np.array(X_test)\n",
        "X_test\n",
        "X_test=np.reshape(X_test,(1,X_test.shape[0],1))\n",
        "pred_price2=model.predict(X_test)\n",
        "print(pred_price2)"
      ],
      "metadata": {
        "id": "xdVFLLJvS7wH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nice!, let's see what was the actual value:"
      ],
      "metadata": {
        "id": "5zfVSLq2YtWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['High'].iloc[-3]"
      ],
      "metadata": {
        "id": "WJlfYbvaS71s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This time the difference was:"
      ],
      "metadata": {
        "id": "7unEBZsmYyg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['High'].iloc[-3]-pred_price2"
      ],
      "metadata": {
        "id": "-tIiUC1PYnjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To compute a new prediction let's use the same logic as before:"
      ],
      "metadata": {
        "id": "AAXIAT3DY5ez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "last_8_days=new_df[-8:].values\n",
        "X_test=[]\n",
        "X_test=np.append(last_8_days,pred_price)\n",
        "X_test=np.append(X_test,pred_price2)\n",
        "X_test=np.array(X_test)\n",
        "X_test\n",
        "X_test=np.reshape(X_test,(1,X_test.shape[0],1))\n",
        "pred_price3=model.predict(X_test)\n",
        "print(pred_price3)"
      ],
      "metadata": {
        "id": "MfqjGekJYnmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Actual value:"
      ],
      "metadata": {
        "id": "fi5uksjFY_L7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['High'].iloc[-2]"
      ],
      "metadata": {
        "id": "K4Pjio4_Ynpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Difference:"
      ],
      "metadata": {
        "id": "KoBRYpIoZGUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['High'].iloc[-2]-pred_price3"
      ],
      "metadata": {
        "id": "YN3BOS2WYnsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_7_days=new_df[-7:].values\n",
        "X_test=[]\n",
        "X_test=np.append(last_7_days, pred_price)\n",
        "X_test=np.append(X_test, pred_price2)\n",
        "X_test=np.append(X_test, pred_price3)\n",
        "X_test=np.array(X_test)\n",
        "X_test\n",
        "X_test=np.reshape(X_test,(1,X_test.shape[0],1))\n",
        "pred_price4=model.predict(X_test)\n",
        "print(pred_price4)"
      ],
      "metadata": {
        "id": "YQHJBnsrYnvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['High'].iloc[-1]"
      ],
      "metadata": {
        "id": "_QgrXKsXYnzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['High'].iloc[-1]-pred_price4"
      ],
      "metadata": {
        "id": "JaoKl2iUYn1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's see the four actual and predicted future values:"
      ],
      "metadata": {
        "id": "qKidr80rZVSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.High.iloc[-4], df.High.iloc[-3], df.High.iloc[-2], df.High.iloc[-1]"
      ],
      "metadata": {
        "id": "cq8goHULYn48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_price, pred_price2, pred_price3, pred_price4"
      ],
      "metadata": {
        "id": "GeF0dTx2Yn8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code will help us visualize these values in a table and plot:"
      ],
      "metadata": {
        "id": "EYjbVaS-ZgI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "actual_prices=np.array([df.High.iloc[-4], df.High.iloc[-3], df.High.iloc[-2], df.High.iloc[-1]])\n",
        "pred_prices=np.array([float(pred_price),float(pred_price2),float(pred_price3),float(pred_price4)])"
      ],
      "metadata": {
        "id": "2Jr3Bsu2Yn_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual_prices, pred_prices"
      ],
      "metadata": {
        "id": "gpdtlco5S75Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data={'Actual values':[df.High.iloc[-4],df.High.iloc[-3],df.High.iloc[-2],df.High.iloc[-1]],\n",
        "      'Predicted values':[float(pred_price),float(pred_price2),float(pred_price3),float(pred_price4)]}\n",
        "\n",
        "pd.DataFrame(data, index=['2020-11-17','2020-11-18','2020-11-19','2020-11-20'])"
      ],
      "metadata": {
        "id": "oNpLXJdHS78I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\tActual values\tPredicted values\n",
        "#2020-11-17\t3623.110107\t3641.089355\n",
        "#2020-11-18\t3619.090088\t3657.960449\n",
        "#2020-11-19\t3585.219971\t3672.406494\n",
        "#2020-11-20\t3581.229980\t3688.468506"
      ],
      "metadata": {
        "id": "AUi6VdUjZrxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "nNiYl2-iZu0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eCCHPFoLqZza"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}